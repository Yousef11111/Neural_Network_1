# Neural_Network_1
How do parameters  influence on results?
What if we increase dropout?
What if we increase epochs?
What if we inrease the first parameter of Dense function?
If we have higher dropout, it means that we're decreasing notification on training and consequently we'll have lower accuracy,
but when the number of epochs increase, the number of training is increased, and we usually reach the higher accuracy.
We are supposed to choose a good model at first, 'cause if our model is changed into ruined model like what I have considered
here, our result will be changed. So as I think the most important part is having a good model.
